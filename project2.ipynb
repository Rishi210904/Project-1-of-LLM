{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rishi210904/Project-1-of-LLM/blob/main/project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKkyM_gllFFz",
        "outputId": "f418b715-c650-465c-e53d-010d50b6ae32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.1-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.4/491.4 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.1 dill-0.3.8 fsspec-2025.3.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.5.3)\n",
            "Collecting llms-from-scratch\n",
            "  Downloading llms_from_scratch-1.0.6-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (2.6.0+cu124)\n",
            "Collecting jupyterlab>=4.0 (from llms-from-scratch)\n",
            "  Downloading jupyterlab-4.4.2-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (0.9.0)\n",
            "Requirement already satisfied: matplotlib>=3.7.1 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (3.10.0)\n",
            "Requirement already satisfied: tensorflow>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (2.18.0)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (4.67.1)\n",
            "Requirement already satisfied: numpy<2.1,>=1.26 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (2.2.2)\n",
            "Collecting pip>=25.0.1 (from llms-from-scratch)\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pytest>=8.3.5 in /usr/local/lib/python3.11/dist-packages (from llms-from-scratch) (8.3.5)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (0.28.1)\n",
            "Requirement already satisfied: ipykernel>=6.5.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (6.17.1)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (5.7.2)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyter_server-2.15.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (0.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (24.2)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (75.2.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (6.4.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from jupyterlab>=4.0->llms-from-scratch) (5.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->llms-from-scratch) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.1->llms-from-scratch) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.1->llms-from-scratch) (2025.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=8.3.5->llms-from-scratch) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=8.3.5->llms-from-scratch) (1.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (2.32.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->llms-from-scratch) (0.37.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.5.1->llms-from-scratch) (2024.11.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.3.0->llms-from-scratch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.3.0->llms-from-scratch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.3.0->llms-from-scratch) (1.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=2.18.0->llms-from-scratch) (0.45.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (0.16.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (24.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.0.3->jupyterlab>=4.0->llms-from-scratch) (3.0.2)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (23.1.0)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (5.10.4)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.21.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.8.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core->jupyterlab>=4.0->llms-from-scratch) (4.3.7)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (4.23.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.18.0->llms-from-scratch) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.18.0->llms-from-scratch) (2.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.18.0->llms-from-scratch) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.18.0->llms-from-scratch) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.18.0->llms-from-scratch) (3.1.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.0->jupyterlab>=4.0->llms-from-scratch) (1.3.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (21.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab>=4.0->llms-from-scratch) (0.24.0)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.11/dist-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (6.0.2)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.21.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.11/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (3.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.8.4)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (24.11.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=6.5.0->jupyterlab>=4.0->llms-from-scratch) (0.2.13)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch) (2.22)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch)\n",
            "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading llms_from_scratch-1.0.6-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab-4.4.2-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.15.0-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.0-py3-none-any.whl (36 kB)\n",
            "Downloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: uri-template, types-python-dateutil, rfc3986-validator, rfc3339-validator, python-json-logger, pip, overrides, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, json5, jedi, fqdn, async-lru, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jupyter-server-terminals, jupyter-client, arrow, nvidia-cusolver-cu12, isoduration, jupyter-events, jupyter-server, jupyterlab-server, jupyter-lsp, jupyterlab, llms-from-scratch\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.16.0\n",
            "    Uninstalling jupyter-server-1.16.0:\n",
            "      Successfully uninstalled jupyter-server-1.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "notebook 6.5.7 requires jupyter-client<8,>=5.3.4, but you have jupyter-client 8.6.3 which is incompatible.\n",
            "jupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arrow-1.3.0 async-lru-2.0.5 fqdn-1.5.1 isoduration-20.11.0 jedi-0.19.2 json5-0.12.0 jupyter-client-8.6.3 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.15.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.2 jupyterlab-server-2.27.3 llms-from-scratch-1.0.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 overrides-7.7.0 pip-25.1.1 python-json-logger-3.3.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 types-python-dateutil-2.9.0.20241206 uri-template-1.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install tiktoken\n",
        "!pip install safetensors\n",
        "!pip install llms-from-scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EXMzZpXplqfU"
      },
      "outputs": [],
      "source": [
        "#importing important libraries\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import tiktoken\n",
        "from llms_from_scratch.ch04 import GPTModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HIagjAvhmAEJ"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "ds_full = load_dataset(\"fancyzhx/ag_news\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8DW7-UTmPAc",
        "outputId": "3c0b6915-daf7-4c43-b6b4-919635e3ff48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['text', 'label'],\n",
            "    num_rows: 50000\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the full dataset\n",
        "ds_full= load_dataset(\"fancyzhx/ag_news\", split=\"train\")\n",
        "\n",
        "# Select the first 30,000 rows\n",
        "ds = ds_full.select(range(50000))\n",
        "\n",
        "# We are verifying that the first 30k rows are taken as a new dataset\n",
        "print(ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hQizQAakmWM5"
      },
      "outputs": [],
      "source": [
        "# first split:\n",
        "split_1 = ds.train_test_split(test_size=0.4, stratify_by_column=\"label\", seed=123)\n",
        "train_ds = split_1[\"train\"]\n",
        "temp_ds = split_1[\"test\"]\n",
        "\n",
        "# Second split: Val vs Test (from temp_ds)\n",
        "split_2 = temp_ds.train_test_split(test_size=0.5, stratify_by_column=\"label\", seed=123)\n",
        "val_ds = split_2[\"train\"]\n",
        "test_ds = split_2[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uQICSR_Wm45D"
      },
      "outputs": [],
      "source": [
        "train_df = train_ds.to_pandas()\n",
        "val_df = val_ds.to_pandas()\n",
        "test_df = test_ds.to_pandas()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ukLRkSfNm6ph",
        "outputId": "0a20773e-446b-4e1e-b88e-6c007b3f6744"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  Insurance Companies Try Out Auto Black Boxes B...      3\n",
              "1  Israel Talks Tough to Arafat Silvan Shalom cal...      0\n",
              "2  Sony leans on discount retailers Japanese elec...      2\n",
              "3  GE warned over perks for ex-chief US industria...      2\n",
              "4  Truckers call off week-long strike  Joint pane...      2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72f6660d-64e5-4328-a3a1-4c5ec40f1430\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Insurance Companies Try Out Auto Black Boxes B...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Israel Talks Tough to Arafat Silvan Shalom cal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sony leans on discount retailers Japanese elec...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GE warned over perks for ex-chief US industria...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Truckers call off week-long strike  Joint pane...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72f6660d-64e5-4328-a3a1-4c5ec40f1430')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-72f6660d-64e5-4328-a3a1-4c5ec40f1430 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-72f6660d-64e5-4328-a3a1-4c5ec40f1430');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7430f883-3651-435d-b6e5-568227e04d81\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7430f883-3651-435d-b6e5-568227e04d81')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7430f883-3651-435d-b6e5-568227e04d81 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 30000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30000,\n        \"samples\": [\n          \"Greek School Bus Crash Kills 7, Injures At Least 24 In Greece, a schoolbus filled with teenage students bound for the Paralympic Games has crashed on the way to Athens, leaving seven passengers dead and at least 24 injured.\",\n          \"Collins, Raiders Crush Buccanneers 30-20 OAKLAND, Calif. - Kerry Collins, the amiable backup quarterback who has repeatedly promised to be ready when needed, replaced injured starter Rich Gannon and calmly directed the Oakland Raiders to an emotional 30-20 victory over the Tampa Bay Buccaneers on Sunday night...\",\n          \"Qwest Shares Rise on Reported Settlement Shares of Qwest Communications rose more than 5 percent in Friday action amid news that the company has agreed to pay \\\\$250 million to end a federal probe of fraudulent accounting practices employed by former management.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "dKl-7Xd5m-YZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ddd507a-9f51-4a00-e756-f95a328d34f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ],
      "source": [
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "val_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))\n",
        "\n",
        "class NewsData(Dataset):\n",
        "    def __init__(self, csv_file, tokenizer, max_length = None, pad_token_id = 50256):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "        # tokenizes the text in the csv file and self.encoded_texts stores the list of encoded sequences.\n",
        "        self.encoded_texts = [\n",
        "            tokenizer.encode(text) for text in self.data[\"text\"]\n",
        "        ]\n",
        "\n",
        "        #if max_length is not given, compute it as the length of the longest tokenized sequence.\n",
        "        if max_length is None:\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "\n",
        "        else:\n",
        "            self.max_length = max_length\n",
        "            # truncate sequences if they are longer than max_length\n",
        "            self.encoded_texts = [\n",
        "                encoded_text[:self.max_length]\n",
        "                for encoded_text in self.encoded_texts\n",
        "            ]\n",
        "\n",
        "        #pad all sequences to the same length (self.max_length) using the pad_token_id.\n",
        "        self.encoded_texts = [\n",
        "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "            for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "    #gets the padded token IDs and label for the index-th example.\n",
        "    def __getitem__(self, index):\n",
        "        encoded = self.encoded_texts[index]\n",
        "        label = self.data.iloc[index][\"label\"]\n",
        "        return (\n",
        "            torch.tensor(encoded, dtype=torch.long),\n",
        "            torch.tensor(label, dtype=torch.long)\n",
        "        ) #returns the encoded sequence and label as PyTorch tensors.\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    #computes and returns the length of the longest sequence in self.encoded_texts.\n",
        "    def _longest_encoded_length(self):\n",
        "        max_length = 0\n",
        "        for encoded_text in self.encoded_texts:\n",
        "            encoded_length = len(encoded_text)\n",
        "            if encoded_length > max_length:\n",
        "                max_length = encoded_length\n",
        "        return max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "D1P4MnhLnyDl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf0f1ed6-d68f-4e46-e603-4e9f7ee19e4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875 training batches\n",
            "625 validation batches\n",
            "625 test batches\n"
          ]
        }
      ],
      "source": [
        "train_dataset = NewsData(\n",
        "    csv_file = \"train.csv\",\n",
        "    max_length = None,\n",
        "    tokenizer = tokenizer\n",
        ")\n",
        "\n",
        "val_dataset = NewsData(\n",
        "    csv_file=\"validation.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "test_dataset = NewsData(\n",
        "    csv_file=\"test.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "num_workers = 2\n",
        "batch_size = 16 #each batch will contain 16 samples\n",
        "torch.manual_seed(123)\n",
        "\n",
        "'''\n",
        "loads data from train_dataset.\n",
        "shuffle=True: randomly shuffles the data each epoch — important for training to reduce bias.\n",
        "drop_last=True: drops the last batch if it has fewer than 8 samples — useful for ensuring consistent batch sizes.\n",
        "'''\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset = val_dataset,\n",
        "    batch_size = batch_size,\n",
        "    num_workers = num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset = test_dataset,\n",
        "    batch_size = batch_size,\n",
        "    num_workers = num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEoowv3VoNBS",
        "outputId": "b25702f5-4dbd-4357-d9c7-126adddd9ec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy version: 2.0.2\n",
            "torch version: 2.6.0+cu124\n",
            "safetensors version: 0.5.3\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "pkgs = [\"numpy\", \"torch\", \"safetensors\"]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ROf4rDWqoOaK",
        "outputId": "8076c9a3-e652-4893-d05c-52192d0fbe30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n{\\n    \"vocab_size\": 50257,\\n    \"context_length\": 1024,\\n    \"drop_rate\": 0.0,\\n    \"qkv_bias\": True,\\n    \"emb_dim\": 768,\\n    \"n_layers\": 12,\\n    \"n_heads\": 12\\n}\\nafter adding the model specific parameters.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 1024, # Context length\n",
        "    \"drop_rate\": 0.0,       # Dropout rate\n",
        "    \"qkv_bias\": True        # Query-key-value bias\n",
        "}\n",
        "\n",
        "#this dictionary defines different GPT-2 model variants\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\" #we choose which model to use.\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "#above, we add the model-specific parameters (like emb_dim, n_layers, n_heads) to the base config, resulting in one complete config dictionary.\n",
        "\n",
        "'''\n",
        "{\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,\n",
        "    \"drop_rate\": 0.0,\n",
        "    \"qkv_bias\": True,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_layers\": 12,\n",
        "    \"n_heads\": 12\n",
        "}\n",
        "after adding the model specific parameters.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "K2PR3OI0ob-e"
      },
      "outputs": [],
      "source": [
        "#downloads and loads a pretrained GPT-2 model checkpoint from Hugging Face using safetensors.\n",
        "import os\n",
        "import urllib.request #for downloading files via HTTP.\n",
        "from safetensors.torch import load_file #from the safetensors package—efficient and safe model weight loading\n",
        "\n",
        "\n",
        "#maps the human-readable CHOOSE_MODEL name to the directory used on Hugging Face.\n",
        "URL_DIR = {\n",
        "  \"gpt2-small (124M)\": \"gpt2\",\n",
        "  \"gpt2-medium (355M)\": \"gpt2-medium\",\n",
        "  \"gpt2-large (774M)\": \"gpt2-large\",\n",
        "  \"gpt2-xl (1558M)\": \"gpt2-xl\"\n",
        "}\n",
        "\n",
        "#the Hugging Face URL to the safetensors file for the selected model.\n",
        "url = f\"https://huggingface.co/openai-community/{URL_DIR[CHOOSE_MODEL]}/resolve/main/model.safetensors\"\n",
        "#output_file: local filename for saving the file (e.g., model-gpt2.safetensors).\n",
        "output_file = f\"model-{URL_DIR[CHOOSE_MODEL]}.safetensors\"\n",
        "\n",
        "#downloads the file only if it's not already saved locally.\n",
        "if not os.path.exists(output_file):\n",
        "    urllib.request.urlretrieve(url, output_file)\n",
        "\n",
        "#loads the model weights as a state_dict using the safetensors format.\n",
        "state_dict = load_file(output_file)\n",
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(right.detach())\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe.weight\"])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte.weight\"])\n",
        "\n",
        "    for b in range(len(gpt.trf_blocks)):\n",
        "        q_w, k_w, v_w = torch.chunk(\n",
        "            params[f\"h.{b}.attn.c_attn.weight\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = torch.chunk(\n",
        "            params[f\"h.{b}.attn.c_attn.bias\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[f\"h.{b}.attn.c_proj.weight\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[f\"h.{b}.attn.c_proj.bias\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[f\"h.{b}.mlp.c_fc.weight\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[f\"h.{b}.mlp.c_fc.bias\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[f\"h.{b}.mlp.c_proj.weight\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[f\"h.{b}.mlp.c_proj.bias\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[f\"h.{b}.ln_1.weight\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[f\"h.{b}.ln_1.bias\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[f\"h.{b}.ln_2.weight\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[f\"h.{b}.ln_2.bias\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"ln_f.weight\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"ln_f.bias\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte.weight\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4g3SOuGmpBP5"
      },
      "outputs": [],
      "source": [
        "gpt = GPTModel(BASE_CONFIG)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "load_weights_into_gpt(gpt, state_dict)\n",
        "gpt.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z68b06GipMcy",
        "outputId": "6a6bbb61-cca1-4e9f-ff6e-f404ae14f25d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text:\n",
            " mistakes make you grow up.\n",
            "\n",
            "\"I'm not going to be a kid anymore,\" he said. \"I'm going to be a grown man.\"\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from llms_from_scratch.ch05 import generate, text_to_token_ids, token_ids_to_text\n",
        "torch.manual_seed(123)\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate(\n",
        "    model=gpt.to(device),\n",
        "    idx=text_to_token_ids(\"mistakes make you grow\", tokenizer).to(device),\n",
        "    max_new_tokens=30,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    top_k=1,\n",
        "    temperature=1.0\n",
        ")\n",
        "\n",
        "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "OXNEvzWlpwFS"
      },
      "outputs": [],
      "source": [
        "for param in gpt.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "torch.manual_seed(123)\n",
        "num_classes = 4\n",
        "\n",
        "gpt.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)\n",
        "\n",
        "for param in gpt.trf_blocks[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "\n",
        "'''\n",
        "Unfreezes the final layer normalization layer (final_norm).\n",
        "this layer processes the model output just before the classification head.\n",
        "making it trainable helps the model better normalize the adapted transformer block output before classification.\n",
        "'''\n",
        "for param in gpt.final_norm.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "oXqoZ4YeqJcj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "236feb8b-2dea-4d74-a43f-e30dfd4cc614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 23.75%\n",
            "Validation accuracy: 28.75%\n",
            "Test accuracy: 27.50%\n"
          ]
        }
      ],
      "source": [
        "def calc_accuracy_loader(data_loader, model, device, num_batches = None):\n",
        "    model.eval() #put the model in evaluation mode\n",
        "    correct_predictions, num_examples = 0, 0 #these will count how many predictions were correct vs. total examples.\n",
        "\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits = model(input_batch)[:, -1, :]  # logits of last output token\n",
        "            predicted_labels = torch.argmax(logits, dim=-1) #takes the class with the highest score.\n",
        "\n",
        "            num_examples += predicted_labels.shape[0]\n",
        "            correct_predictions += (predicted_labels == target_batch).sum().item() #Compares it to the actual labels and accumulates correct predictions.\n",
        "        else:\n",
        "            break\n",
        "    return correct_predictions / num_examples\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "gpt.to(device)\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_accuracy = calc_accuracy_loader(train_loader, gpt, device, num_batches=10)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, gpt, device, num_batches=10)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, gpt, device, num_batches=10)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "77Bc9JCZq9PF"
      },
      "outputs": [],
      "source": [
        "#this function calculates the cross-entropy loss for a single batch of data using the GPT-based model.\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "    loss = torch.nn.functional.cross_entropy(logits, target_batch, label_smoothing=0.1)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "VreS1117rL4f"
      },
      "outputs": [],
      "source": [
        "#this function computes the average loss over multiple batches from a DataLoader.\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hyxwgD_rORw",
        "outputId": "53d1fb59-300e-4b44-8fdc-690aaceb7973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 2.097\n",
            "Validation loss: 2.561\n",
            "Test loss: 2.565\n"
          ]
        }
      ],
      "source": [
        "#computes the accuracy on the three datasets.\n",
        "with torch.no_grad(): #disables gradient tracking\n",
        "    train_loss = calc_loss_loader(train_loader, gpt, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, gpt, device, num_batches=5)\n",
        "    test_loss = calc_loss_loader(test_loader, gpt, device, num_batches=5)\n",
        "\n",
        "print(f\"Training loss: {train_loss:.3f}\")\n",
        "print(f\"Validation loss: {val_loss:.3f}\")\n",
        "print(f\"Test loss: {test_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "iPyOBEX8rUWu"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter):\n",
        "\n",
        "    # Initialize lists to track losses and examples seen\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Calculate accuracy after each epoch\n",
        "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "        train_accs.append(train_accuracy)\n",
        "        val_accs.append(val_accuracy)\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYwevreNrmhD",
        "outputId": "4411da81-ea4d-4a3f-bde6-0a929194bb0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 1.063, Val loss 1.050\n",
            "Ep 1 (Step 000100): Train loss 1.015, Val loss 0.994\n",
            "Ep 1 (Step 000200): Train loss 0.951, Val loss 0.934\n",
            "Ep 1 (Step 000300): Train loss 0.917, Val loss 0.921\n",
            "Ep 1 (Step 000400): Train loss 0.981, Val loss 0.981\n",
            "Ep 1 (Step 000500): Train loss 0.977, Val loss 0.941\n",
            "Ep 1 (Step 000600): Train loss 0.916, Val loss 0.918\n",
            "Ep 1 (Step 000700): Train loss 0.968, Val loss 0.932\n",
            "Ep 1 (Step 000800): Train loss 0.918, Val loss 0.909\n",
            "Ep 1 (Step 000900): Train loss 0.961, Val loss 0.925\n",
            "Ep 1 (Step 001000): Train loss 0.970, Val loss 0.939\n",
            "Ep 1 (Step 001100): Train loss 0.912, Val loss 0.915\n",
            "Ep 1 (Step 001200): Train loss 0.991, Val loss 0.986\n",
            "Ep 1 (Step 001300): Train loss 0.951, Val loss 0.917\n",
            "Ep 1 (Step 001400): Train loss 0.901, Val loss 0.904\n",
            "Ep 1 (Step 001500): Train loss 0.968, Val loss 0.951\n",
            "Ep 1 (Step 001600): Train loss 0.894, Val loss 0.922\n",
            "Ep 1 (Step 001700): Train loss 0.921, Val loss 0.916\n",
            "Ep 1 (Step 001800): Train loss 0.957, Val loss 0.889\n",
            "Training accuracy: 70.50% | Validation accuracy: 71.62%\n",
            "Training completed in 71.92 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "torch.manual_seed(123)\n",
        "#uses the AdamW optimizer\n",
        "optimizer = torch.optim.AdamW(gpt.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 1\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "    gpt, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=100, eval_iter=50,\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    # Create a second x-axis for examples seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2dfTZgr4evXf"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
      ],
      "metadata": {
        "id": "aIzJmgJWe0Cz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "899cff5e-a84e-478b-d873-59c3abc7d627"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_statement(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
        "    model.eval()\n",
        "\n",
        "    # Prepare inputs to the model\n",
        "    input_ids = tokenizer.encode(text)\n",
        "    supported_context_length = model.pos_emb.weight.shape[0]\n",
        "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "\n",
        "    # Pad sequences\n",
        "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    # Model inference\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)[:, -1, :]  # Logits of last output token\n",
        "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    # Label mapping\n",
        "    label_map = {\n",
        "        0: \"World\",\n",
        "        1: \"Sports/film\",\n",
        "        2: \"Business\",\n",
        "        3: \"Sci/Tech\"\n",
        "    }\n",
        "\n",
        "    return label_map.get(predicted_label, \"Unknown\")"
      ],
      "metadata": {
        "id": "lk8wJEEMe3ht"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = (\n",
        "    \"The brutalist grabs best film award at oscars\"\n",
        ")\n",
        "\n",
        "print(classify_statement(\n",
        "    text_1, gpt, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "id": "1FgRK1UrfFmD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eb2d3c4-f93f-4798-a250-b1c0ae311271"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "World\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        "    \"'Godfather of AI’ says AI is like a cute tiger cub—unless you know it won’t turn on you, you should worry\"\n",
        ")\n",
        "\n",
        "print(classify_statement(\n",
        "    text_2, gpt, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "id": "P3R8lI99fP-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f1c20e5-1700-4cab-f2c6-b80cb2b100c4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "World\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}