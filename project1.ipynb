{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNrMzdMraSvUQNM8nTF+uIo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rishi210904/Project-1-of-LLM/blob/main/project1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken matplotlib torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcF12TEV-KBb",
        "outputId": "f9be3f04-6658-4702-cc58-59e39a1aac9d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "P2egLFep9_8R",
        "outputId": "dbf4b1c9-2b2a-4f21-ddbc-698ff9713096"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 8.927, Val loss 8.662\n",
            "Ep 1 (Step 000050): Train loss 5.251, Val loss 5.287\n",
            "Ep 1 (Step 000100): Train loss 5.332, Val loss 5.038\n",
            "Ep 1 (Step 000150): Train loss 4.822, Val loss 4.873\n",
            "Ep 1 (Step 000200): Train loss 4.716, Val loss 4.766\n",
            "Ep 1 (Step 000250): Train loss 4.576, Val loss 4.695\n",
            "Now, Kitty, you may cough as much as you choose, and\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\\n",
            "Ep 2 (Step 000300): Train loss 4.349, Val loss 4.641\n",
            "Ep 2 (Step 000350): Train loss 4.344, Val loss 4.631\n",
            "Ep 2 (Step 000400): Train loss 4.451, Val loss 4.575\n",
            "Ep 2 (Step 000450): Train loss 4.196, Val loss 4.549\n",
            "Ep 2 (Step 000500): Train loss 3.751, Val loss 4.508\n",
            "Ep 2 (Step 000550): Train loss 3.814, Val loss 4.475\n",
            "Now, Kitty, you may cough as much as you choose, and\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\\n",
            "Ep 3 (Step 000600): Train loss 4.308, Val loss 4.449\n",
            "Ep 3 (Step 000650): Train loss 3.676, Val loss 4.463\n",
            "Ep 3 (Step 000700): Train loss 3.848, Val loss 4.399\n",
            "Ep 3 (Step 000750): Train loss 3.991, Val loss 4.376\n",
            "Ep 3 (Step 000800): Train loss 3.821, Val loss 4.383\n",
            "Ep 3 (Step 000850): Train loss 3.844, Val loss 4.361\n",
            "Now, Kitty, you may cough as much as you choose, and\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\\n",
            "Ep 4 (Step 000900): Train loss 3.763, Val loss 4.322\n",
            "Ep 4 (Step 000950): Train loss 3.625, Val loss 4.336\n",
            "Ep 4 (Step 001000): Train loss 3.639, Val loss 4.330\n",
            "Ep 4 (Step 001050): Train loss 3.628, Val loss 4.334\n",
            "Ep 4 (Step 001100): Train loss 3.901, Val loss 4.313\n",
            "Ep 4 (Step 001150): Train loss 3.678, Val loss 4.313\n",
            "Now, Kitty, you may cough as much as you choose, and\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\\n",
            "Ep 5 (Step 001200): Train loss 3.453, Val loss 4.298\n",
            "Ep 5 (Step 001250): Train loss 3.249, Val loss 4.314\n",
            "Ep 5 (Step 001300): Train loss 3.370, Val loss 4.321\n",
            "Ep 5 (Step 001350): Train loss 3.314, Val loss 4.331\n",
            "Ep 5 (Step 001400): Train loss 3.213, Val loss 4.290\n",
            "Ep 5 (Step 001450): Train loss 3.326, Val loss 4.268\n",
            "Now, Kitty, you may cough as much as you choose, and\\r\",\"\\r\",\"\\r\",\"“I am not be so much to be a\\r\",\"”\\r\",\"”\\r\",\"”\\r\",\"“I am sure you,”\\r\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "import matplotlib\n",
        "import tiktoken\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 1024, # Context length : represents the model's maximum input token count\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False       # Query-Key-Value bias\n",
        "}\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "batch =torch.randn(2, 5)\n",
        "\n",
        "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
        "out = layer(batch)\n",
        "\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if len(x.shape) == 2:\n",
        "            x = x.unsqueeze(1)\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "batch_size, d_in = batch.shape # Only unpack 2 values\n",
        "context_length = batch.shape[1] # Assign context_length separately\n",
        "# batch_size, context_length, d_in = batch.shape # Original problematic line\n",
        "d_out = 2 # Output dimension\n",
        "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
        "out = mha(batch)\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        # Use a placeholder for TransformerBlock\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        # Use a placeholder for LayerNorm\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        x = (x - mean) / (std + self.eps)\n",
        "        x = self.scale * x + self.shift\n",
        "        return x\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval()\n",
        "class GPTDataset(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "def create_dataloader(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDataset(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (batch, n_tokens) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "x = torch.rand(2, 4, 768)  # Shape: [batch_size, num_tokens, emb_dim]\n",
        "block = TransformerBlock(GPT_CONFIG_124M)\n",
        "out = block(x)\n",
        "\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "file_path = \"both book.txt\"\n",
        "url = \"https://github.com/Rishi210904/Project-1-of-LLM/blob/74a48b2cf2068dfa2b0eb9f2c057b34ab6e0ecf2/both%20book.txt\"\n",
        "if not os.path.exists(file_path):\n",
        "    urllib.request.urlretrieve(url, file_path)\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"Now, Kitty, you may cough as much as you choose,\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context, tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text))\n",
        "train_data = text[:split_idx]\n",
        "val_data = text[split_idx:]\n",
        "train_loader = create_dataloader(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride= GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
        "\n",
        "\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
        "    start_context=\"Now, Kitty, you may cough as much as you choose,\", tokenizer=tokenizer\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_path = input(\"Enter the file path: \")\n",
        "url = input(\"Enter the URL: \")\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    urllib.request.urlretrieve(url, file_path)\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "num_epochs=int(input(\"Enter the number of epochs: \"))\n",
        "train_model_simple(model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,start_context = input(\"Enter the starting context for text generation: \"),tokenizer=tokenizer)\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "     # Moved input here\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context # Use start_context from input\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen, start_context # Return start_context\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5FGOapY16Dx",
        "outputId": "d4be896d-a91c-43f7-f4c2-c03e1ab5f9be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the file path: /content/The Project Gutenberg eBook of Prid.txt\n",
            "Enter the URL: https://www.gutenberg.org/cache/epub/1342/pg1342.txt\n",
            "Enter the number of epochs: 1\n",
            "Enter the starting context for text generation: Now, Kitty, you may cough as much as you choose,\n",
            "Ep 1 (Step 000000): Train loss 2.079, Val loss 5.142\n",
            "Ep 1 (Step 000050): Train loss 1.659, Val loss 5.356\n",
            "Now, Kitty, you may cough as much as you choose, as I have been my dear Lydia, I shall pull it to       for I am married to be  not help saying, I must confess that I will be my family, my dear aunt, if you\n"
          ]
        }
      ]
    }
  ]
}