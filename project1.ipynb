{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM/gY9XUFwCBKixLShEI7Bu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rishi210904/Project-1-of-LLM/blob/main/project1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken matplotlib torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcF12TEV-KBb",
        "outputId": "7a5f7d13-8eb3-4983-9785-a2b8e459819f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "P2egLFep9_8R",
        "outputId": "1c8f8816-7fd4-4f21-9433-874f7087877c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 10.332, Val loss 10.293\n",
            "Ep 1 (Step 000050): Train loss 5.636, Val loss 5.900\n",
            "Now, Kitty, you may cough as much as you choose, and                                                 \n",
            "Ep 2 (Step 000100): Train loss 5.226, Val loss 5.361\n",
            "Ep 2 (Step 000150): Train loss 4.431, Val loss 5.123\n",
            "Now, Kitty, you may cough as much as you choose, and                                                 \n",
            "Ep 3 (Step 000200): Train loss 4.726, Val loss 4.995\n",
            "Ep 3 (Step 000250): Train loss 3.937, Val loss 4.892\n",
            "Now, Kitty, you may cough as much as you choose, and  the whole party.  the whole of the   she had been  the subject, and the the whole of the the whole of the  the whole of the the whole party, and she\n",
            "Ep 4 (Step 000300): Train loss 4.042, Val loss 4.868\n",
            "Now, Kitty, you may cough as much as you choose, I have been             “I am not know, I have been        “I am not to be so much as you have been so much as\n",
            "Ep 5 (Step 000350): Train loss 3.526, Val loss 4.833\n",
            "Ep 5 (Step 000400): Train loss 3.357, Val loss 4.854\n",
            "Now, Kitty, you may cough as much as you choose, and  ”   ” ”   ” “I have you?”      ”   ” ”  ”  �\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "import matplotlib\n",
        "import tiktoken\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 1024, # Context length : represents the model's maximum input token count\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False       # Query-Key-Value bias\n",
        "}\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "batch =torch.randn(2, 5)\n",
        "\n",
        "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
        "out = layer(batch)\n",
        "\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if len(x.shape) == 2:\n",
        "            x = x.unsqueeze(1)\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "batch_size, d_in = batch.shape # Only unpack 2 values\n",
        "context_length = batch.shape[1] # Assign context_length separately\n",
        "# batch_size, context_length, d_in = batch.shape # Original problematic line\n",
        "d_out = 2 # Output dimension\n",
        "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
        "out = mha(batch)\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        # Use a placeholder for TransformerBlock\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        # Use a placeholder for LayerNorm\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        x = (x - mean) / (std + self.eps)\n",
        "        x = self.scale * x + self.shift\n",
        "        return x\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval()\n",
        "class GPTDataset(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "def create_dataloader(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDataset(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (batch, n_tokens) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "x = torch.rand(2, 4, 768)  # Shape: [batch_size, num_tokens, emb_dim]\n",
        "block = TransformerBlock(GPT_CONFIG_124M)\n",
        "out = block(x)\n",
        "\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "file_path = \"The Project Gutenberg eBook of Prid.txt\"\n",
        "url = \"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\"\n",
        "if not os.path.exists(file_path):\n",
        "    urllib.request.urlretrieve(url, file_path)\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"Now, Kitty, you may cough as much as you choose,\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context, tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text))\n",
        "train_data = text[:split_idx]\n",
        "val_data = text[split_idx:]\n",
        "train_loader = create_dataloader(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride= GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
        "\n",
        "\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
        "    start_context=\"Now, Kitty, you may cough as much as you choose,\", tokenizer=tokenizer\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_path = input(\"Enter the file path: \")\n",
        "url = input(\"Enter the URL: \")\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    urllib.request.urlretrieve(url, file_path)\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "train_model_simple(model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,start_context = input(\"Enter the starting context for text generation: \"),tokenizer=tokenizer)\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "     # Moved input here\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context # Use start_context from input\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen, start_context # Return start_context\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a5FGOapY16Dx",
        "outputId": "f3f04de6-3796-4acb-ddc6-85922ce12548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the file path: /content/The Project Gutenberg eBook of Prid.txt\n",
            "Enter the URL: https://www.gutenberg.org/cache/epub/1342/pg1342.txt\n",
            "Enter the starting context for text generation: Now, Kitty, you may cough as much as you choose\n",
            "Ep 1 (Step 000000): Train loss 3.175, Val loss 4.874\n",
            "Ep 1 (Step 000050): Train loss 2.894, Val loss 4.906\n",
            "Now, Kitty, you may cough as much as you choose, and  ” “I am sure of your pardon.” “I am sure you do not do not do not be in the same time, and “I_ ” ” \n",
            "Ep 2 (Step 000100): Train loss 2.446, Val loss 5.013\n",
            "Ep 2 (Step 000150): Train loss 2.146, Val loss 5.098\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-82d4b9d5e237>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m train_model_simple(model, train_loader, val_loader, optimizer, device,\n\u001b[0m\u001b[1;32m     13\u001b[0m     num_epochs=num_epochs, eval_freq=50, eval_iter=5,start_context = input(\"Enter the starting context for text generation: \"),tokenizer=tokenizer)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-c095c4514de0>\u001b[0m in \u001b[0;36mtrain_model_simple\u001b[0;34m(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;31m# Print a sample text after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         generate_and_print_sample(\n\u001b[0m\u001b[1;32m    383\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         )\n",
            "\u001b[0;32m<ipython-input-19-c095c4514de0>\u001b[0m in \u001b[0;36mgenerate_and_print_sample\u001b[0;34m(model, tokenizer, device, start_context)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_to_token_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         token_ids = generate_text_simple(\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-c095c4514de0>\u001b[0m in \u001b[0;36mgenerate_text_simple\u001b[0;34m(model, idx, max_new_tokens, context_size)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;31m# Get the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_cond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# Focus only on the last time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-c095c4514de0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, in_idx)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtok_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrf_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-c095c4514de0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Shortcut connection for feed forward block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mshortcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_shortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-c095c4514de0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1913\u001b[0m     \u001b[0;31m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m     \u001b[0;31m# https://github.com/pytorch/pytorch/pull/115074\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_parameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_parameters\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}